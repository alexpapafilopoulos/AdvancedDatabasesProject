{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2 with SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "import time\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"Query 2 - SQL API\").getOrCreate()\n",
    "\n",
    "# Define the schema for the crime data\n",
    "crimeSchema = StructType([\n",
    "    StructField(\"DR_NO\", StringType(), True),\n",
    "    StructField(\"Date Rptd\", StringType(), True),\n",
    "    StructField(\"DATE OCC\", StringType(), True),\n",
    "    StructField(\"TIME OCC\", StringType(), True),\n",
    "    StructField(\"AREA\", StringType(), True),\n",
    "    StructField(\"AREA NAME\", StringType(), True),\n",
    "    StructField(\"Rpt Dist No\", StringType(), True),\n",
    "    StructField(\"Part 1-2\", StringType(), True),\n",
    "    StructField(\"Crm Cd\", StringType(), True),\n",
    "    StructField(\"Crm Cd Desc\", StringType(), True),\n",
    "    StructField(\"Mocodes\", StringType(), True),\n",
    "    StructField(\"Vict Age\", StringType(), True),\n",
    "    StructField(\"Vict Sex\", StringType(), True),\n",
    "    StructField(\"Vict Descent\", StringType(), True),\n",
    "    StructField(\"Premis Cd\", StringType(), True),\n",
    "    StructField(\"Premis Desc\", StringType(), True),\n",
    "    StructField(\"Weapon Used Cd\", StringType(), True),\n",
    "    StructField(\"Weapon Desc\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"Status Desc\", StringType(), True),\n",
    "    StructField(\"Crm Cd 1\", StringType(), True),\n",
    "    StructField(\"Crm Cd 2\", StringType(), True),\n",
    "    StructField(\"Crm Cd 3\", StringType(), True),\n",
    "    StructField(\"Crm Cd 4\", StringType(), True),\n",
    "    StructField(\"LOCATION\", StringType(), True),\n",
    "    StructField(\"Cross Street\", StringType(), True),\n",
    "    StructField(\"LAT\", StringType(), True),\n",
    "    StructField(\"LON\", StringType(), True)\n",
    "])\n",
    "\n",
    "# File paths for crime data\n",
    "file1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Read the crime data\n",
    "df1 = spark.read.csv(file1, header=True, schema=crimeSchema)\n",
    "df2 = spark.read.csv(file2, header=True, schema=crimeSchema)\n",
    "\n",
    "# Union the datasets\n",
    "df = df1.union(df2)\n",
    "\n",
    "# Register table for SQL operations\n",
    "df.createOrReplaceTempView(\"crime_data\")\n",
    "\n",
    "# Convert `DATE OCC` to timestamp and extract the year\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *, \n",
    "        YEAR(TO_TIMESTAMP(`DATE OCC`, 'MM/dd/yyyy hh:mm:ss a')) AS Year\n",
    "    FROM crime_data\n",
    "\"\"\").createOrReplaceTempView(\"crime_with_year\")\n",
    "\n",
    "# Calculate total and closed cases, and closed percentage directly\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Year,\n",
    "        `AREA NAME`, \n",
    "        COUNT(*) AS Total_Cases,\n",
    "        (SUM(CASE \n",
    "            WHEN `Status Desc` NOT IN ('UNK', 'Invest Cont') THEN 1 \n",
    "            ELSE 0 \n",
    "        END) / COUNT(*)) * 100 AS Closed_Percentage\n",
    "    FROM crime_with_year\n",
    "    GROUP BY Year, `AREA NAME`\n",
    "\"\"\").createOrReplaceTempView(\"cases_with_percentage\")\n",
    "\n",
    "# Rank departments by closed percentage\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Year, \n",
    "        `AREA NAME`, \n",
    "        Total_Cases, \n",
    "        Closed_Percentage, \n",
    "        RANK() OVER (PARTITION BY Year ORDER BY Closed_Percentage DESC) AS Rank\n",
    "    FROM cases_with_percentage\n",
    "\"\"\").createOrReplaceTempView(\"ranked_departments\")\n",
    "\n",
    "# Filter top 3 departments per year and sort by year and rank\n",
    "top_departments = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Year, \n",
    "        `AREA NAME`, \n",
    "        Closed_Percentage, \n",
    "        Rank \n",
    "    FROM ranked_departments\n",
    "    WHERE Rank <= 3\n",
    "    ORDER BY Year, Rank\n",
    "\"\"\")\n",
    "\n",
    "# Show results\n",
    "top_departments.show(60, truncate=False)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
