{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2 with Parquet and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, year, lit, when\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "\n",
    "# Δημιουργία SparkSession\n",
    "spark = SparkSession.builder.appName(\"Convert to Parquet\").getOrCreate()\n",
    "\n",
    "crimeSchema = StructType([\n",
    "    StructField(\"DR_NO\", StringType(), True),\n",
    "    StructField(\"Date Rptd\", StringType(), True),\n",
    "    StructField(\"DATE OCC\", StringType(), True),\n",
    "    StructField(\"TIME OCC\", StringType(), True),\n",
    "    StructField(\"AREA\", StringType(), True),\n",
    "    StructField(\"AREA NAME\", StringType(), True),\n",
    "    StructField(\"Rpt Dist No\", StringType(), True),\n",
    "    StructField(\"Part 1-2\", StringType(), True),\n",
    "    StructField(\"Crm Cd\", StringType(), True),\n",
    "    StructField(\"Crm Cd Desc\", StringType(), True),\n",
    "    StructField(\"Mocodes\", StringType(), True),\n",
    "    StructField(\"Vict Age\", StringType(), True),\n",
    "    StructField(\"Vict Sex\", StringType(), True),\n",
    "    StructField(\"Vict Descent\", StringType(), True),\n",
    "    StructField(\"Premis Cd\", StringType(), True),\n",
    "    StructField(\"Premis Desc\", StringType(), True),\n",
    "    StructField(\"Weapon Used Cd\", StringType(), True),\n",
    "    StructField(\"Weapon Desc\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"Status Desc\", StringType(), True),\n",
    "    StructField(\"Crm Cd 1\", StringType(), True),\n",
    "    StructField(\"Crm Cd 2\", StringType(), True),\n",
    "    StructField(\"Crm Cd 3\", StringType(), True),\n",
    "    StructField(\"Crm Cd 4\", StringType(), True),\n",
    "    StructField(\"LOCATION\", StringType(), True),\n",
    "    StructField(\"Cross Street\", StringType(), True),\n",
    "    StructField(\"LAT\", StringType(), True),\n",
    "    StructField(\"LON\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Ορισμός διευθύνσεων αρχείων\n",
    "file1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "parquet_file_path = \"s3://groups-bucket-dblab-905418150721/group2/completeCrimeParquet\"\n",
    "\n",
    "df_csv1 = spark.read.csv(file1, header=True, schema=crimeSchema)\n",
    "df_csv2 = spark.read.csv(file2, header=True, schema=crimeSchema)\n",
    "\n",
    "df_csv = df_csv1.union(df_csv2)\n",
    "\n",
    "df_csv.write.mode(\"overwrite\").parquet(parquet_file_path)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = spark.read.parquet(parquet_file_path)\n",
    "\n",
    "# Adjust the format to match the actual data format (e.g., 'MM/dd/yyyy hh:mm:ss a')\n",
    "df = df.withColumn(\"DATE OCC\", F.to_timestamp(F.col(\"DATE OCC\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "\n",
    "# Step 3: Extract year from `DATE OCC`\n",
    "cases_with_year_df = df.withColumn(\"Year\", F.year(F.col(\"DATE OCC\")))\n",
    "\n",
    "# Step 4: Filter for valid years (optional)\n",
    "cases_with_year_df = cases_with_year_df.filter(F.col(\"Year\").isNotNull())\n",
    "\n",
    "# Step 5: Filter out the \"UNK\" and \"Invest Cont\" statuses\n",
    "filtered_df = cases_with_year_df.filter(\n",
    "    (F.col(\"Status Desc\") != \"UNK\") & (F.col(\"Status Desc\") != \"Invest Cont\")\n",
    ")\n",
    "\n",
    "# Step 6: Group by Year and Department, calculate total and closed percentages\n",
    "percentages_df = cases_with_year_df.groupBy(\"Year\", \"AREA NAME\").agg(\n",
    "    F.count(\"*\").alias(\"Total_Cases\"),\n",
    "    F.sum(\n",
    "        F.when((F.col(\"Status Desc\") != \"UNK\") & (F.col(\"Status Desc\") != \"Invest Cont\"), 1).otherwise(0)\n",
    "    ).alias(\"Closed_Cases\")\n",
    ").withColumn(\n",
    "    \"Closed_Percentage\", (F.col(\"Closed_Cases\") / F.col(\"Total_Cases\")) * 100\n",
    ")\n",
    "\n",
    "# Step 7: Rank departments by closed percentage for each year\n",
    "window_spec = Window.partitionBy(\"Year\").orderBy(F.col(\"Closed_Percentage\").desc())\n",
    "ranked_df = percentages_df.withColumn(\"Rank\", F.row_number().over(window_spec))\n",
    "\n",
    "# Step 8: Filter top 3 departments per year\n",
    "top_3_departments_df = ranked_df.filter(F.col(\"Rank\") <= 3)\n",
    "\n",
    "# Step 9: Sort results by year and rank\n",
    "sorted_result_df = top_3_departments_df.orderBy(\"Year\", \"Rank\")\n",
    "\n",
    "# Show results\n",
    "sorted_result_df.select(\"Year\", \"AREA NAME\", \"Closed_Percentage\", \"Rank\").show(60, truncate=False)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
