{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1 using RDD API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Δημιουργία SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Query 1 - RDD \") \\\n",
    "    .config(\"spark.executor.instances\", 4) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# File paths\n",
    "file1 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2010_to_2019_20241101.csv\"\n",
    "file2 = \"s3://initial-notebook-data-bucket-dblab-905418150721/CrimeData/Crime_Data_from_2020_to_Present_20241101.csv\"\n",
    "\n",
    "# Function to process a single file and compute counts\n",
    "def process_file_rdd(file_path):\n",
    "    # Read file using spark.read.csv from SparkSession\n",
    "    data = spark.read.csv(file_path, header=True)\n",
    "    \n",
    "    # Convert DataFrame to RDD\n",
    "    rdd = data.rdd\n",
    "    \n",
    "    # Get column indices dynamically\n",
    "    victim_age_idx = data.columns.index(\"Vict Age\")\n",
    "    crime_desc_idx = data.columns.index(\"Crm Cd Desc\")\n",
    "    \n",
    "    # Process RDD\n",
    "    age_groups = rdd.filter(\n",
    "        lambda row: row[victim_age_idx] is not None and row[victim_age_idx].isdigit() and \"AGGRAVATED ASSAULT\" in row[crime_desc_idx]\n",
    "    ).map(\n",
    "        lambda row: int(row[victim_age_idx])\n",
    "    ).map(\n",
    "        lambda age: (\n",
    "            \"Children\" if age < 18 else \n",
    "            \"Young Adults\" if 18 <= age <= 24 else \n",
    "            \"Adults\" if 25 <= age <= 64 else \n",
    "            \"Elderly\",\n",
    "            1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Aggregate counts by age group\n",
    "    counts = age_groups.reduceByKey(lambda a, b: a + b)\n",
    "    return counts\n",
    "\n",
    "# Process each file independently\n",
    "result_rdd1 = process_file_rdd(file1)\n",
    "result_rdd2 = process_file_rdd(file2)\n",
    "\n",
    "# Combine results from both files\n",
    "combined_rdd = result_rdd1.union(result_rdd2).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sort by count in descending order\n",
    "sorted_results = combined_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Collect and display results\n",
    "for age_group, count in sorted_results.collect():\n",
    "    print(f\"{age_group}: {count}\")\n",
    "\n",
    "# Stop timing and print out the execution duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
